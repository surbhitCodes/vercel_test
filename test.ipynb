{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# API Details\n",
    "URL = \"https://core-api-green-bird-4902.fly.dev/analyze-complexity\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "PAYLOAD = {\"text\": \"Aristotle was the smartest of his time\"}\n",
    "\n",
    "# Test parameters\n",
    "NUM_REQUESTS = 20  # Total number of requests\n",
    "CONCURRENCY = 5    # Max concurrent requests\n",
    "\n",
    "async def send_request(session, semaphore):\n",
    "    \"\"\"Send a single request while respecting concurrency limits.\"\"\"\n",
    "    async with semaphore:\n",
    "        start = time.perf_counter()\n",
    "        try:\n",
    "            async with session.post(URL, json=PAYLOAD, headers=HEADERS) as resp:\n",
    "                await resp.text()  # Read response content\n",
    "        except Exception as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "        end = time.perf_counter()\n",
    "        return end - start\n",
    "\n",
    "async def benchmark():\n",
    "    \"\"\"Run benchmark test with concurrent requests.\"\"\"\n",
    "    semaphore = asyncio.Semaphore(CONCURRENCY)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [send_request(session, semaphore) for _ in range(NUM_REQUESTS)]\n",
    "        latencies = await asyncio.gather(*tasks)\n",
    "\n",
    "    avg_latency = sum(latencies) / len(latencies)\n",
    "    rps = len(latencies) / sum(latencies)\n",
    "\n",
    "    print(\"\\n=== Benchmark Results ===\")\n",
    "    print(f\"Total Requests: {NUM_REQUESTS}\")\n",
    "    print(f\"Concurrency Level: {CONCURRENCY}\")\n",
    "    print(f\"Average Latency: {avg_latency*1000:.2f} ms\")\n",
    "    print(f\"Requests Per Second (RPS): {rps:.2f}\")\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Run benchmark test and measure total execution time.\"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    await benchmark()\n",
    "    total_time = time.perf_counter() - start_time\n",
    "\n",
    "    print(f\"Total Time Taken: {total_time:.2f}s\")\n",
    "    print(f\"Average Requests per Second (RPS): {NUM_REQUESTS/total_time:.2f}\")\n",
    "\n",
    "# Run the test\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# API Details\n",
    "URL = \"https://knowledge-graph-broken-surf-6085.fly.dev/extract-knowledge-graph\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "PAYLOAD = {\"text\": \"Aristotle was the smartest of his time\"}\n",
    "\n",
    "# Test parameters\n",
    "NUM_REQUESTS = 20  # Total number of requests\n",
    "CONCURRENCY = 5    # Max concurrent requests\n",
    "\n",
    "async def send_request(session, semaphore):\n",
    "    \"\"\"Send a single request while respecting concurrency limits.\"\"\"\n",
    "    async with semaphore:\n",
    "        start = time.perf_counter()\n",
    "        try:\n",
    "            async with session.post(URL, json=PAYLOAD, headers=HEADERS) as resp:\n",
    "                await resp.text()  # Read response content\n",
    "        except Exception as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "        end = time.perf_counter()\n",
    "        return end - start\n",
    "\n",
    "async def benchmark():\n",
    "    \"\"\"Run benchmark test with concurrent requests.\"\"\"\n",
    "    semaphore = asyncio.Semaphore(CONCURRENCY)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [send_request(session, semaphore) for _ in range(NUM_REQUESTS)]\n",
    "        latencies = await asyncio.gather(*tasks)\n",
    "\n",
    "    avg_latency = sum(latencies) / len(latencies)\n",
    "    rps = len(latencies) / sum(latencies)\n",
    "\n",
    "    print(\"\\n=== Benchmark Results ===\")\n",
    "    print(f\"Total Requests: {NUM_REQUESTS}\")\n",
    "    print(f\"Concurrency Level: {CONCURRENCY}\")\n",
    "    print(f\"Average Latency: {avg_latency*1000:.2f} ms\")\n",
    "    print(f\"Requests Per Second (RPS): {rps:.2f}\")\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Run benchmark test and measure total execution time.\"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    await benchmark()\n",
    "    total_time = time.perf_counter() - start_time\n",
    "\n",
    "    print(f\"Total Time Taken: {total_time:.2f}s\")\n",
    "    print(f\"Average Requests per Second (RPS): {NUM_REQUESTS/total_time:.2f}\")\n",
    "\n",
    "# Run the test\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_url = \"https://surbhitcodes--core-api-fastapi.modal.run\"\n",
    "kg_url = \"https://surbhitcodes--knowledge-graph-api-fastapi.modal.run\"\n",
    "ta_url =\"https://surbhitcodes--text-analysis-api-fastapi.modal.run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://surbhitcodes--text-analysis-api-fastapi.modal.run/extract-analyze-complexity-stream\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Core API Load Test Results\n",
      "Total Requests: 100\n",
      "Successful Requests: 100\n",
      "Failed Requests: 0\n",
      "Peak Concurrent Requests: 100\n",
      "Total Test Duration: 13.482s\n",
      "Latency (Avg: 4.371s, Min: 2.501s, Max: 13.438s)\n",
      "\n",
      "Text Analysis API Load Test Results\n",
      "Total Requests: 100\n",
      "Successful Requests: 100\n",
      "Failed Requests: 0\n",
      "Peak Concurrent Requests: 100\n",
      "Total Test Duration: 9.111s\n",
      "Latency (Avg: 4.231s, Min: 2.483s, Max: 9.066s)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "\n",
    "core_url = \"https://surbhitcodes--core-api-fastapi.modal.run/analyze-complexity\"\n",
    "kg_url = \"https://surbhitcodes--knowledge-graph-api-fastapi.modal.run/extract-knowledge-graph\"\n",
    "ta_url = \"https://surbhitcodes--text-analysis-api-fastapi.modal.run/extract-analyze-complexity-stream\"\n",
    "\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "payload = {\"text\": \"Aristotle was the smartest of his time\"}\n",
    "NUM_REQUESTS = 100\n",
    "\n",
    "concurrent_requests = 0\n",
    "peak_concurrency = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def send_request(url):\n",
    "    global concurrent_requests, peak_concurrency\n",
    "\n",
    "    with lock:\n",
    "        concurrent_requests += 1\n",
    "        peak_concurrency = max(peak_concurrency, concurrent_requests)\n",
    "\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=headers, timeout=20)\n",
    "        latency = (time.time() - start_time) \n",
    "        return response.status_code, latency, response.text[:200]  # Include error message\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return \"ERROR\", None, str(e)  # Capture error message\n",
    "    finally:\n",
    "        with lock:\n",
    "            concurrent_requests -= 1\n",
    "\n",
    "def test_api(url, api_name):\n",
    "    global peak_concurrency\n",
    "    peak_concurrency = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=NUM_REQUESTS) as executor:\n",
    "        futures = [executor.submit(send_request, url) for _ in range(NUM_REQUESTS)]\n",
    "        results = [future.result() for future in as_completed(futures)]\n",
    "    total_time = (time.time() - start_time)\n",
    "\n",
    "    success_responses = [latency for status, latency, _ in results if status == 200]\n",
    "    failed_responses = [(status, msg) for status, _, msg in results if status != 200]\n",
    "\n",
    "    success_count = len(success_responses)\n",
    "    error_count = len(failed_responses)\n",
    "    avg_latency = round(sum(success_responses) / len(success_responses), 3) if success_responses else 0\n",
    "    max_latency = round(max(success_responses), 3) if success_responses else 0\n",
    "    min_latency = round(min(success_responses), 3) if success_responses else 0\n",
    "\n",
    "    print(f\"\\n{api_name} API Load Test Results\")\n",
    "    print(f\"Total Requests: {NUM_REQUESTS}\")\n",
    "    print(f\"Successful Requests: {success_count}\")\n",
    "    print(f\"Failed Requests: {error_count}\")\n",
    "    print(f\"Peak Concurrent Requests: {peak_concurrency}\")\n",
    "    print(f\"Total Test Duration: {round(total_time, 3)}s\")\n",
    "    print(f\"Latency (Avg: {avg_latency}s, Min: {min_latency}s, Max: {max_latency}s)\")\n",
    "\n",
    "    if failed_responses:\n",
    "        print(\"\\n3 Sample Error Responses:\")\n",
    "        for status, msg in failed_responses[:3]:\n",
    "            print(f\"Status: {status}, Error: {msg}\")\n",
    "\n",
    "test_api(core_url, \"Core\")\n",
    "# test_api(kg_url, \"Knowledge Graph\")\n",
    "test_api(ta_url, \"Text Analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
